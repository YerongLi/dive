{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'decision_trees.decision_tree'; 'decision_trees' is not a package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Importing our from scratch models\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdecision_trees\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecision_tree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DecisionTree\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdecision_trees\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrandom_forest\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdecision_trees\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01madaboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AdaBoostClassifier\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'decision_trees.decision_tree'; 'decision_trees' is not a package"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import sys\n",
    "from sklearn import datasets, model_selection, metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Importing our from scratch models\n",
    "from decision_trees.decision_tree import DecisionTree\n",
    "from decision_trees.random_forest import RandomForestClassifier\n",
    "from decision_trees.adaboost import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTree Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: (112, 4)\n",
      "Train Shape: (38, 4)\n"
     ]
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "\n",
    "X = np.array(iris.data)\n",
    "Y = np.array(iris.target)\n",
    "iris_feature_names = iris.feature_names\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=0.25, random_state=0)\n",
    "print(\"Train Shape:\", X_train.shape)\n",
    "print(\"Train Shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DecisionTree' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Building the tree\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m my_tree \u001b[38;5;241m=\u001b[39m \u001b[43mDecisionTree\u001b[49m(max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, min_samples_leaf\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, min_information_gain\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      3\u001b[0m my_tree\u001b[38;5;241m.\u001b[39mtrain(X_train, Y_train)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DecisionTree' is not defined"
     ]
    }
   ],
   "source": [
    "# Building the tree\n",
    "my_tree = DecisionTree(max_depth=4, min_samples_leaf=1, min_information_gain=0)\n",
    "my_tree.train(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â Let's see the tree\n",
    "my_tree.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the Train performance\n",
    "train_preds = my_tree.predict(X_set=X_train)\n",
    "print(\"TRAIN PERFORMANCE\")\n",
    "print(\"Train size\", len(Y_train))\n",
    "print(\"True preds\", sum(train_preds == Y_train))\n",
    "print(\"Train Accuracy\", sum(train_preds == Y_train) / len(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the Test performance\n",
    "test_preds = my_tree.predict(X_set=X_test)\n",
    "print(\"TEST PERFORMANCE\")\n",
    "print(\"Test size\", len(Y_test))\n",
    "print(\"True preds\", sum(test_preds == Y_test))\n",
    "print(\"Accuracy\", sum(test_preds == Y_test) / len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "plt.bar(range(len(my_tree.feature_importances)), \n",
    "        list(my_tree.feature_importances.values()), tick_label=iris_feature_names)\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel(\"Feature Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on Breast Cancer Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = datasets.load_breast_cancer()\n",
    "X = data.data\n",
    "Y = data.target\n",
    "breast_cancer_feature_names = data.feature_names\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "print(\"Train Shape:\", X_train.shape)\n",
    "print(\"Train Shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the tree\n",
    "my_tree_2 = DecisionTree(max_depth=4, min_samples_leaf=5, min_information_gain=0.05)\n",
    "my_tree_2.train(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tree_2.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the Train performance\n",
    "train_preds = my_tree_2.predict(X_set=X_train)\n",
    "print(\"TRAIN PERFORMANCE\")\n",
    "print(\"Train size\", len(Y_train))\n",
    "print(\"True preds\", sum(train_preds == Y_train))\n",
    "print(\"Train Accuracy\", sum(train_preds == Y_train) / len(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the Test performance\n",
    "test_preds = my_tree_2.predict(X_set=X_test)\n",
    "print(\"TEST PERFORMANCE\")\n",
    "print(\"Test size\", len(Y_test))\n",
    "print(\"True preds\", sum(test_preds == Y_test))\n",
    "print(\"Accuracy\", sum(test_preds == Y_test) / len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "plt.bar(range(len(my_tree_2.feature_importances)), \n",
    "        list(my_tree_2.feature_importances.values()), tick_label=breast_cancer_feature_names)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.ylabel(\"Feature Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on Diabetes Data (from OpenML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = datasets.fetch_openml(name=\"diabetes\", as_frame=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_features = np.array(diabetes.data)\n",
    "print(diabetes_features.shape)\n",
    "diabetes_labels = np.array([y==\"tested_positive\" for y in diabetes.target]).astype(int)\n",
    "print(diabetes_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(diabetes_features, diabetes_labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets see how model performs with different max_depth thresholds\n",
    "\n",
    "train_accuracy_dict = {}\n",
    "test_accuracy_dict = {}\n",
    "# depth_occured = {}\n",
    "\n",
    "for depth in range(2, 21):\n",
    "    tree_model = DecisionTree(max_depth=depth, min_samples_leaf=1)\n",
    "    tree_model.train(X_train, Y_train)\n",
    "\n",
    "    # depth_occured[depth] = tree_model.current_de\n",
    "\n",
    "    # Train performance\n",
    "    train_preds = tree_model.predict(X_set=X_train)\n",
    "    train_accuracy = sum(train_preds == Y_train) / len(Y_train)\n",
    "    train_accuracy_dict[depth] = train_accuracy\n",
    "\n",
    "    # Test performance\n",
    "    test_preds = tree_model.predict(X_set=X_test)\n",
    "    test_accuracy = sum(test_preds == Y_test) / len(Y_test)\n",
    "    test_accuracy_dict[depth] = test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_accuracy_dict.keys(), train_accuracy_dict.values(), label=\"Train\")\n",
    "plt.plot(test_accuracy_dict.keys(), test_accuracy_dict.values(), label=\"Test\")\n",
    "plt.title(\"Accuracy vs Depth for Diabetes Dataset\")\n",
    "plt.xlabel(\"Max Depth Threshold\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.ylim(bottom=0.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can see that the tree starts to overfit after max_depth exceeds 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_tree_model = DecisionTree(max_depth=5, min_samples_leaf=1)\n",
    "opt_tree_model.train(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = opt_tree_model.predict(X_set=X_train)\n",
    "print(\"TRAIN PERFORMANCE\")\n",
    "print(\"Train size\", len(Y_train))\n",
    "print(\"True preds\", sum(train_preds == Y_train))\n",
    "print(\"Accuracy\", sum(train_preds == Y_train) / len(Y_train))\n",
    "\n",
    "test_preds = opt_tree_model.predict(X_set=X_test)\n",
    "print(\"TEST PERFORMANCE\")\n",
    "print(\"Test size\", len(Y_test))\n",
    "print(\"True preds\", sum(test_preds == Y_test))\n",
    "print(\"Accuracy\", sum(test_preds == Y_test) / len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_tree_model.print_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "plt.bar(range(len(opt_tree_model.feature_importances)), \n",
    "        list(opt_tree_model.feature_importances.values()), tick_label=diabetes.feature_names)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.ylabel(\"Feature Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "\n",
    "X = np.array(iris.data)\n",
    "Y = np.array(iris.target)\n",
    "iris_feature_names = iris.feature_names\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=0.25, random_state=0)\n",
    "print(\"Train Shape:\", X_train.shape)\n",
    "print(\"Train Shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building random forest model\n",
    "rf_model = RandomForestClassifier(n_base_learner=50, numb_of_features_splitting=\"sqrt\")\n",
    "rf_model.train(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performans increases when compared to the basic DecisionTree\n",
    "train_preds = rf_model.predict(X_set=X_train)\n",
    "print(\"TRAIN PERFORMANCE\")\n",
    "print(\"Train size\", len(Y_train))\n",
    "print(\"True preds\", sum(train_preds == Y_train))\n",
    "print(\"Accuracy\", sum(train_preds == Y_train) / len(Y_train))\n",
    "\n",
    "test_preds = rf_model.predict(X_set=X_test)\n",
    "print(\"TEST PERFORMANCE\")\n",
    "print(\"Test size\", len(Y_test))\n",
    "print(\"True preds\", sum(test_preds == Y_test))\n",
    "print(\"Accuracy\", sum(test_preds == Y_test) / len(Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on Breast Cancer Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = datasets.load_breast_cancer()\n",
    "X = data.data\n",
    "Y = data.target\n",
    "breast_cancer_feature_names = data.feature_names\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "print(\"Train Shape:\", X_train.shape)\n",
    "print(\"Train Shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building random forest model\n",
    "rf_model_2 = RandomForestClassifier(n_base_learner=100, \n",
    "                                    max_depth=4, min_samples_leaf=5, min_information_gain=0.05)\n",
    "rf_model_2.train(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performans increases when compared to the basic DecisionTree\n",
    "train_preds = rf_model_2.predict(X_set=X_train)\n",
    "print(\"TRAIN PERFORMANCE\")\n",
    "print(\"Train size\", len(Y_train))\n",
    "print(\"True preds\", sum(train_preds == Y_train))\n",
    "print(\"Accuracy\", sum(train_preds == Y_train) / len(Y_train))\n",
    "\n",
    "test_preds = rf_model_2.predict(X_set=X_test)\n",
    "print(\"TEST PERFORMANCE\")\n",
    "print(\"Test size\", len(Y_test))\n",
    "print(\"True preds\", sum(test_preds == Y_test))\n",
    "print(\"Accuracy\", sum(test_preds == Y_test) / len(Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on Diabetes Data (from OpenML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = datasets.fetch_openml(name=\"diabetes\", as_frame=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_features = np.array(diabetes.data)\n",
    "print(diabetes_features.shape)\n",
    "diabetes_labels = np.array([y==\"tested_positive\" for y in diabetes.target]).astype(int)\n",
    "print(diabetes_labels.shape)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(diabetes_features, diabetes_labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model_3 = RandomForestClassifier(n_base_learner=200, numb_of_features_splitting=None,\n",
    "                                     max_depth=5, min_samples_leaf=1)\n",
    "rf_model_3.train(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance increases when compared to basic decision tree\n",
    "train_preds = rf_model_3.predict(X_set=X_train)\n",
    "print(\"TRAIN PERFORMANCE\")\n",
    "print(\"Train size\", len(Y_train))\n",
    "print(\"True preds\", sum(train_preds == Y_train))\n",
    "print(\"Accuracy\", sum(train_preds == Y_train) / len(Y_train))\n",
    "\n",
    "test_preds = rf_model_3.predict(X_set=X_test)\n",
    "print(\"TEST PERFORMANCE\")\n",
    "print(\"Test size\", len(Y_test))\n",
    "print(\"True preds\", sum(test_preds == Y_test))\n",
    "print(\"Accuracy\", sum(test_preds == Y_test) / len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance of RandomForest Model\n",
    "plt.bar(range(len(rf_model_3.feature_importances)), \n",
    "        list(rf_model_3.feature_importances), tick_label=diabetes.feature_names)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.ylabel(\"Feature Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "\n",
    "X = np.array(iris.data)\n",
    "Y = np.array(iris.target)\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "model = AdaBoostClassifier(n_base_learner=50)\n",
    "model.train(X_train, y_train)\n",
    "\n",
    "train_accuracy = sum(model.predict(X=X_train) == y_train) / len(y_train)\n",
    "test_accuracy = sum(model.predict(X=X_test) == y_test) / len(y_test)\n",
    "print(\"Our Model Performance\")\n",
    "print(\"Train Accuracy: \", train_accuracy)\n",
    "print(\"Test Accuracy: \", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "\n",
    "X = np.array(iris.data)\n",
    "Y = np.array(iris.target)\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "model = sklearn.ensemble.AdaBoostClassifier(n_estimators=50)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "train_accuracy = sum(model.predict(X=X_train) == y_train) / len(y_train)\n",
    "test_accuracy = sum(model.predict(X=X_test) == y_test) / len(y_test)\n",
    "print(\"Sklearn Model Performance\")\n",
    "print(\"Train Accuracy: \", train_accuracy)\n",
    "print(\"Test Accuracy: \", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on Breast Cancer Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_breast_cancer()\n",
    "\n",
    "X = np.array(data.data)\n",
    "Y = np.array(data.target)\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "model = AdaBoostClassifier(n_base_learner=50)\n",
    "model.train(X_train, y_train)\n",
    "\n",
    "train_accuracy = sum(model.predict(X=X_train) == y_train) / len(y_train)\n",
    "test_accuracy = sum(model.predict(X=X_test) == y_test) / len(y_test)\n",
    "print(\"Our Model Performance\")\n",
    "print(\"Train Accuracy: \", train_accuracy)\n",
    "print(\"Test Accuracy: \", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_breast_cancer()\n",
    "\n",
    "X = np.array(data.data)\n",
    "Y = np.array(data.target)\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "model = sklearn.ensemble.AdaBoostClassifier(n_estimators=50)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "train_accuracy = sum(model.predict(X=X_train) == y_train) / len(y_train)\n",
    "test_accuracy = sum(model.predict(X=X_test) == y_test) / len(y_test)\n",
    "print(\"Sklearn Model Performance\")\n",
    "print(\"Train Accuracy: \", train_accuracy)\n",
    "print(\"Test Accuracy: \", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on Diabetes Data (from OpenML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = datasets.fetch_openml(name=\"diabetes\", as_frame=False)\n",
    "diabetes_features = np.array(diabetes.data)\n",
    "print(diabetes_features.shape)\n",
    "diabetes_labels = np.array([y==\"tested_positive\" for y in diabetes.target]).astype(int)\n",
    "print(diabetes_labels.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(diabetes_features, diabetes_labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AdaBoostClassifier(n_base_learner=50)\n",
    "model.train(X_train, y_train)\n",
    "\n",
    "train_accuracy = sum(model.predict(X=X_train) == y_train) / len(y_train)\n",
    "test_accuracy = sum(model.predict(X=X_test) == y_test) / len(y_test)\n",
    "print(\"Our Model Performance\")\n",
    "print(\"Train Accuracy: \", train_accuracy)\n",
    "print(\"Test Accuracy: \", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sklearn.ensemble.AdaBoostClassifier(n_estimators=50)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "train_accuracy = sum(model.predict(X=X_train) == y_train) / len(y_train)\n",
    "test_accuracy = sum(model.predict(X=X_test) == y_test) / len(y_test)\n",
    "print(\"Sklearn Model Performance\")\n",
    "print(\"Train Accuracy: \", train_accuracy)\n",
    "print(\"Test Accuracy: \", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Simulations for Understanding the # of Base Learners in AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_breast_cancer()\n",
    "\n",
    "X = np.array(data.data)\n",
    "Y = np.array(data.target)\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "\n",
    "# model = AdaBoostClassifier(n_base_learner=10)\n",
    "# model.train(X_train, y_train)\n",
    "\n",
    "train_accuracy_list = []\n",
    "test_accuracy_list = []\n",
    "for n_base_learner in range(1, 150, 3):\n",
    "    model = AdaBoostClassifier(n_base_learner)\n",
    "    model.train(X_train, y_train)\n",
    "    train_accuracy_list.append(sum(model.predict(X=X_train) == y_train) / len(y_train))\n",
    "    test_accuracy_list.append(sum(model.predict(X=X_test) == y_test) / len(y_test))\n",
    "\n",
    "plt.plot(list(range(1, 150, 3)), train_accuracy_list, color='red', label='train')\n",
    "plt.plot(list(range(1, 150, 3)), test_accuracy_list, color='green', label='test')\n",
    "plt.title(\"Our AdaBoostClassifier Performance\")\n",
    "plt.xlabel('# of Base Learner')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy_list = []\n",
    "test_accuracy_list = []\n",
    "n_estimaters_list = []\n",
    "for n_base_learner in range(1, 150, 3):\n",
    "    model = sklearn.ensemble.AdaBoostClassifier(n_estimators=n_base_learner, learning_rate=0.2, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    train_accuracy_list.append(sum(model.predict(X_train) == y_train) / len(y_train))\n",
    "    test_accuracy_list.append(sum(model.predict(X_test) == y_test) / len(y_test))\n",
    "    n_estimaters_list.append(len(model.estimators_))\n",
    "\n",
    "plt.plot(list(range(1, 150, 3)), train_accuracy_list, color='red', label='train')\n",
    "plt.plot(list(range(1, 150, 3)), test_accuracy_list, color='green', label='test')\n",
    "plt.title(\"Sklearn AdaBoostClassifier Performance\")\n",
    "plt.xlabel('# of Base Learner')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
